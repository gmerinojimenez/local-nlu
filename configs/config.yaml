# Model configuration
model:
  name: "t5-base"  # Changed to T5 for seq2seq generation
  max_input_length: 128
  max_output_length: 256
  dropout: 0.1

# Training configuration
training:
  batch_size: 16
  learning_rate: 2.0e-5
  num_epochs: 5
  warmup_steps: 500
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0

# Data configuration
data:
  raw_data_path: "data/raw/all_origin_utterances_20240626_with_current_nli_response.xlsx"
  processed_data_path: "data/processed/"
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  random_seed: 42

# Paths
paths:
  model_save_dir: "models/"
  logs_dir: "logs/"
  tensorboard_dir: "logs/tensorboard/"

# Evaluation
evaluation:
  metrics: ["accuracy", "f1", "precision", "recall"]
  per_class_metrics: true
